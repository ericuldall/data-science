{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#GA Data Science: Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Plants Database\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "    :Summary Statistics:\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML iris datasets.\n",
      "http://archive.ics.uci.edu/ml/datasets/Iris\n",
      "\n",
      "The famous Iris database, first used by Sir R.A Fisher\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "References\n",
      "----------\n",
      "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "Names = iris.target_names\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96666666666666667"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20)\n",
    "myknn = KNeighborsClassifier(50).fit(X_train, y_train)\n",
    "\n",
    "print(myknn.score(X_test, y_test))\n",
    "\n",
    "1 - np.mean((myknn.predict(X_test) - y_test)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Exercise 1\n",
    "\n",
    "##How does the model perform when you increase the number of neighbors?\n",
    "##How much do the scores vary with different splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cross Validation: Shuffle & Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95999999999999996"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score, ShuffleSplit\n",
    "\n",
    "n_samples = len(y)\n",
    "knn = KNeighborsClassifier(3)\n",
    "cv = ShuffleSplit(n_samples, n_iter=10, test_size=0.3)\n",
    "\n",
    "test_scores = cross_val_score(knn, X, y, cv=cv)\n",
    "test_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Exercise #2\n",
    "##Calculate the cross-validation score for test_sizes of .1 and .9\n",
    "##How does the model perform at the different test sizes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#KFolds Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# generic cross validation function\n",
    "def cross_validate(X, y, classifier, k_fold) :\n",
    "\n",
    "    # derive a set of (random) training and testing indices\n",
    "    k_fold_indices = KFold( len(X), n_folds=k_fold, shuffle=True)\n",
    "    print(list(k_fold_indices))\n",
    "\n",
    "    k_score_total = 0\n",
    "    # for each training and testing slices run the classifier, and score the results\n",
    "    for train_slice, test_slice in k_fold_indices :\n",
    "\n",
    "        model = classifier(X[ train_slice  ],\n",
    "                         y[ train_slice  ])\n",
    "\n",
    "        k_score = model.score(X[ test_slice ],\n",
    "                              y[ test_slice ])\n",
    "\n",
    "        k_score_total += k_score\n",
    "\n",
    "    # return the average accuracy\n",
    "    return k_score_total/k_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([  0,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "        15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "        28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,\n",
      "        42,  43,  44,  45,  46,  47,  48,  50,  51,  52,  53,  54,  55,\n",
      "        56,  57,  58,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "        70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,\n",
      "        83,  85,  86,  87,  90,  91,  93,  94,  95,  96,  97,  98,  99,\n",
      "       100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113,\n",
      "       114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "       128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 140, 142, 143,\n",
      "       144, 145, 146, 147, 149]), array([  1,   2,  41,  49,  59,  84,  88,  89,  92, 106, 127, 131, 139,\n",
      "       141, 148])), (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,  10,  11,  12,  13,\n",
      "        14,  15,  16,  17,  18,  19,  21,  22,  23,  24,  26,  27,  28,\n",
      "        29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  41,  42,\n",
      "        43,  44,  45,  46,  47,  48,  49,  50,  51,  53,  55,  56,  57,\n",
      "        58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "        72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "        85,  86,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "        99, 100, 101, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 118, 120, 121, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143,\n",
      "       144, 145, 146, 148, 149]), array([  9,  20,  25,  40,  52,  54,  71,  87, 102, 103, 108, 119, 122,\n",
      "       137, 147])), (array([  0,   1,   2,   3,   4,   5,   7,   8,   9,  12,  13,  14,  15,\n",
      "        16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "        29,  30,  31,  33,  34,  37,  38,  39,  40,  41,  43,  44,  45,\n",
      "        46,  47,  48,  49,  51,  52,  53,  54,  55,  56,  57,  58,  59,\n",
      "        61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,\n",
      "        74,  75,  76,  77,  78,  79,  80,  82,  83,  84,  85,  87,  88,\n",
      "        89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 102,\n",
      "       103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
      "       116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 129, 130,\n",
      "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144,\n",
      "       145, 146, 147, 148, 149]), array([  6,  10,  11,  32,  35,  36,  42,  50,  60,  81,  86, 101, 125,\n",
      "       128, 142])), (array([  0,   1,   2,   3,   4,   5,   6,   7,   9,  10,  11,  13,  14,\n",
      "        16,  19,  20,  21,  22,  23,  24,  25,  30,  31,  32,  33,  34,\n",
      "        35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,\n",
      "        48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  59,  60,  61,\n",
      "        62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,\n",
      "        75,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,\n",
      "        89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n",
      "       102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
      "       116, 117, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
      "       131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
      "       145, 146, 147, 148, 149]), array([  8,  12,  15,  17,  18,  26,  27,  28,  29,  58,  76, 104, 118,\n",
      "       120, 132])), (array([  0,   1,   2,   3,   4,   6,   8,   9,  10,  11,  12,  13,  14,\n",
      "        15,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "        29,  30,  31,  32,  33,  34,  35,  36,  37,  39,  40,  41,  42,\n",
      "        43,  44,  45,  46,  49,  50,  51,  52,  54,  55,  56,  57,  58,\n",
      "        59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  70,  71,  72,\n",
      "        73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,\n",
      "        86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "        99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "       114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127,\n",
      "       128, 129, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141,\n",
      "       142, 143, 146, 147, 148]), array([  5,   7,  16,  38,  47,  48,  53,  69, 100, 113, 121, 136, 144,\n",
      "       145, 149])), (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  20,  21,  22,  23,  25,  26,  27,\n",
      "        28,  29,  30,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "        42,  43,  44,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "        56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  68,  69,  70,\n",
      "        71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "        84,  86,  87,  88,  89,  90,  91,  92,  94,  95,  97,  99, 100,\n",
      "       101, 102, 103, 104, 106, 107, 108, 109, 110, 112, 113, 114, 115,\n",
      "       117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130,\n",
      "       131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
      "       145, 146, 147, 148, 149]), array([ 19,  24,  31,  45,  66,  67,  85,  93,  96,  98, 105, 111, 116,\n",
      "       124, 134])), (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  22,  24,  25,  26,  27,\n",
      "        28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,\n",
      "        41,  42,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
      "        57,  58,  59,  60,  61,  63,  65,  66,  67,  69,  70,  71,  72,\n",
      "        73,  74,  76,  77,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
      "        88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,\n",
      "       101, 102, 103, 104, 105, 106, 108, 109, 111, 112, 113, 114, 115,\n",
      "       116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129,\n",
      "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
      "       144, 145, 147, 148, 149]), array([ 21,  23,  43,  55,  56,  62,  64,  68,  75,  78, 107, 110, 123,\n",
      "       130, 146])), (array([  0,   1,   2,   3,   5,   6,   7,   8,   9,  10,  11,  12,  14,\n",
      "        15,  16,  17,  18,  19,  20,  21,  23,  24,  25,  26,  27,  28,\n",
      "        29,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "        43,  45,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,\n",
      "        58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "        71,  72,  73,  74,  75,  76,  78,  79,  81,  83,  84,  85,  86,\n",
      "        87,  88,  89,  90,  91,  92,  93,  95,  96,  98,  99, 100, 101,\n",
      "       102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130,\n",
      "       131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
      "       145, 146, 147, 148, 149]), array([  4,  13,  22,  30,  44,  46,  77,  80,  82,  94,  97, 109, 114,\n",
      "       126, 133])), (array([  1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "        15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "        28,  29,  30,  31,  32,  34,  35,  36,  37,  38,  40,  41,  42,\n",
      "        43,  44,  45,  46,  47,  48,  49,  50,  52,  53,  54,  55,  56,\n",
      "        58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "        71,  72,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,\n",
      "        86,  87,  88,  89,  92,  93,  94,  96,  97,  98,  99, 100, 101,\n",
      "       102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
      "       130, 131, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 144,\n",
      "       145, 146, 147, 148, 149]), array([  0,   3,  33,  39,  51,  57,  73,  74,  90,  91,  95, 117, 129,\n",
      "       135, 143])), (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
      "        27,  28,  29,  30,  31,  32,  33,  35,  36,  38,  39,  40,  41,\n",
      "        42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
      "        55,  56,  57,  58,  59,  60,  62,  64,  66,  67,  68,  69,  71,\n",
      "        73,  74,  75,  76,  77,  78,  80,  81,  82,  84,  85,  86,  87,\n",
      "        88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98, 100, 101,\n",
      "       102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 139, 141, 142, 143, 144,\n",
      "       145, 146, 147, 148, 149]), array([ 14,  34,  37,  61,  63,  65,  70,  72,  79,  83,  99, 112, 115,\n",
      "       138, 140]))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96000000000000019"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(X, y, KNeighborsClassifier(3).fit, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
